{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Spectral Certificate Validation\n",
    "\n",
    "## Submission: Koopman + Davis-Kahan/Wedin Detection Pipeline\n",
    "\n",
    "This notebook validates the spectral certificate approach for detecting agent drift vs. creative behavior.\n",
    "\n",
    "**All data are synthetic. No real secrets or external network calls.**\n",
    "\n",
    "### Overview\n",
    "1. Generate synthetic traces (gold/creative/drift)\n",
    "2. Compute spectral certificates for each trace\n",
    "3. Train a classifier and evaluate ROC/AUC\n",
    "4. Analyze Davis-Kahan angle distributions\n",
    "5. Calibrate detection threshold\n",
    "6. Generate validation reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from certificates.spectral_prover import (\n",
    "    compute_detection_statistics,\n",
    "    generate_synthetic_linear_system,\n",
    "    generate_perturbed_trajectory,\n",
    "    trajectory_matrix,\n",
    "    subspace_angle,\n",
    "    davis_kahan_upper_bound,\n",
    ")\n",
    "\n",
    "from analysis.convert_trace import generate_synthetic_traces\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Traces\n",
    "\n",
    "We generate three types of traces:\n",
    "- **Gold**: Smooth, low-noise trajectories (baseline behavior)\n",
    "- **Creative**: Higher variance but still coherent (acceptable exploration)\n",
    "- **Drift**: Divergent trajectories (problematic behavior to detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-traces",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic traces\n",
    "TRACES_DIR = PROJECT_ROOT / 'experiment_traces'\n",
    "\n",
    "N_TRACES = 30  # Per label\n",
    "T = 40  # Timesteps\n",
    "D = 64  # Embedding dimension\n",
    "\n",
    "outputs = generate_synthetic_traces(\n",
    "    TRACES_DIR,\n",
    "    n_gold=N_TRACES,\n",
    "    n_creative=N_TRACES,\n",
    "    n_drift=N_TRACES,\n",
    "    T=T,\n",
    "    d=D,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"Generated traces:\")\n",
    "for label, paths in outputs.items():\n",
    "    print(f\"  {label}: {len(paths)} traces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. Load and Compute Features\n",
    "\n",
    "For each trace, compute:\n",
    "- SVD reconstruction residual\n",
    "- Tail energy (unexplained variance)\n",
    "- Singular gap at rank k\n",
    "- Davis-Kahan angle vs baseline\n",
    "- Koopman prediction residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10  # Rank for spectral analysis\n",
    "\n",
    "def load_traces(traces_dir):\n",
    "    \"\"\"Load all traces from directory.\"\"\"\n",
    "    traces = {'gold': [], 'creative': [], 'drift': []}\n",
    "    for label in traces:\n",
    "        label_dir = traces_dir / label\n",
    "        if not label_dir.exists():\n",
    "            continue\n",
    "        for f in sorted(label_dir.glob('*.json')):\n",
    "            with open(f) as fp:\n",
    "                traces[label].append(json.load(fp))\n",
    "    return traces\n",
    "\n",
    "traces = load_traces(TRACES_DIR)\n",
    "print(f\"Loaded: gold={len(traces['gold'])}, creative={len(traces['creative'])}, drift={len(traces['drift'])}\")\n",
    "\n",
    "# First pass: compute gold baseline\n",
    "gold_features = []\n",
    "for t in traces['gold']:\n",
    "    stats = compute_detection_statistics(t['embeddings'], k=K)\n",
    "    stats['label'] = 'gold'\n",
    "    stats['run_id'] = t['run_id']\n",
    "    gold_features.append(stats)\n",
    "\n",
    "# Get baseline U_k from first gold trace\n",
    "baseline_U = gold_features[0]['U_k'] if gold_features else None\n",
    "\n",
    "# Compute all features with baseline\n",
    "all_features = []\n",
    "for label in ['gold', 'creative', 'drift']:\n",
    "    for t in traces[label]:\n",
    "        stats = compute_detection_statistics(t['embeddings'], k=K, baseline_U=baseline_U)\n",
    "        stats['label'] = label\n",
    "        stats['run_id'] = t['run_id']\n",
    "        all_features.append(stats)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_features)\n",
    "df = df.drop(columns=['U_k'], errors='ignore')\n",
    "\n",
    "print(f\"\\nFeatures computed: {len(df)} traces\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. Feature Distributions by Label\n",
    "\n",
    "Visualize how spectral features separate the three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-distributions",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "\n",
    "features_to_plot = ['residual', 'theoretical_bound', 'tail_energy', \n",
    "                    'dk_angle', 'koopman_residual', 'singular_gap']\n",
    "titles = ['Residual', 'Theoretical Bound', 'Tail Energy',\n",
    "          'Davis-Kahan Angle', 'Koopman Residual', 'Singular Gap']\n",
    "\n",
    "for ax, feat, title in zip(axes.flat, features_to_plot, titles):\n",
    "    for label in ['gold', 'creative', 'drift']:\n",
    "        data = df[df['label'] == label][feat].dropna()\n",
    "        ax.hist(data, bins=15, alpha=0.5, label=label, density=True)\n",
    "    ax.set_xlabel(feat)\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'reports' / 'spectral_validation' / 'feature_distributions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "summary = df.groupby('label')[['residual', 'theoretical_bound', 'tail_energy', \n",
    "                                'dk_angle', 'koopman_residual']].agg(['mean', 'std', 'median'])\n",
    "print(\"\\nSummary Statistics by Label:\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. Classification: Drift vs Creative\n",
    "\n",
    "Train a logistic regression classifier to distinguish drift from non-drift (gold + creative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-classifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "feature_cols = ['residual', 'theoretical_bound', 'tail_energy', \n",
    "                'dk_angle', 'koopman_residual', 'singular_gap', 'pca_explained']\n",
    "\n",
    "df['is_drift'] = (df['label'] == 'drift').astype(int)\n",
    "\n",
    "X = df[feature_cols].fillna(0).values\n",
    "y = df['is_drift'].values\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train with cross-validation\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='roc_auc')\n",
    "\n",
    "print(f\"Cross-validation AUC: {cv_scores.mean():.4f} +/- {cv_scores.std():.4f}\")\n",
    "\n",
    "# Fit final model\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "# Feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'coefficient': model.coef_[0]\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roc-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve\n",
    "y_proba = model.predict_proba(X_scaled)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Find TPR at FPR = 0.05\n",
    "idx = np.where(fpr <= 0.05)[0]\n",
    "if len(idx) > 0:\n",
    "    tpr_at_fpr05 = tpr[idx[-1]]\n",
    "    threshold_at_fpr05 = thresholds[idx[-1]]\n",
    "else:\n",
    "    tpr_at_fpr05 = 0.0\n",
    "    threshold_at_fpr05 = 0.5\n",
    "\n",
    "print(f\"AUC: {roc_auc:.4f}\")\n",
    "print(f\"TPR @ FPR=0.05: {tpr_at_fpr05:.4f}\")\n",
    "print(f\"Threshold @ FPR=0.05: {threshold_at_fpr05:.4f}\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "ax.axvline(x=0.05, color='r', linestyle=':', linewidth=2, label='FPR = 0.05')\n",
    "ax.scatter([fpr[idx[-1]]], [tpr[idx[-1]]], color='red', s=100, zorder=5,\n",
    "           label=f'Operating Point (TPR={tpr_at_fpr05:.2f})')\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curve: Drift Detection', fontsize=14)\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'reports' / 'spectral_validation' / 'roc_curve_notebook.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "## 6. Davis-Kahan Angle Analysis\n",
    "\n",
    "Verify that the Davis-Kahan bound holds empirically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dk-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: dk_angle vs residual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Left: DK angle vs residual\n",
    "for label in ['gold', 'creative', 'drift']:\n",
    "    subset = df[df['label'] == label]\n",
    "    axes[0].scatter(subset['residual'], subset['dk_angle'], \n",
    "                    alpha=0.6, label=label, s=50)\n",
    "axes[0].set_xlabel('Residual')\n",
    "axes[0].set_ylabel('Davis-Kahan Angle (radians)')\n",
    "axes[0].set_title('DK Angle vs Residual')\n",
    "axes[0].legend()\n",
    "\n",
    "# Right: DK angle vs dk_bound\n",
    "valid = df[df['dk_bound'] < 10]  # Filter extreme values\n",
    "axes[1].scatter(valid['dk_bound'], np.sin(valid['dk_angle']), alpha=0.5)\n",
    "axes[1].plot([0, 1], [0, 1], 'r--', linewidth=2, label='sin(Î¸) = bound')\n",
    "axes[1].set_xlabel('Davis-Kahan Upper Bound')\n",
    "axes[1].set_ylabel('sin(DK Angle)')\n",
    "axes[1].set_title('Empirical vs Theoretical Bound')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'reports' / 'spectral_validation' / 'dk_analysis.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "## 7. Calibration Table\n",
    "\n",
    "Compute calibrated thresholds for different FPR levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration table\n",
    "target_fprs = [0.01, 0.05, 0.10, 0.20]\n",
    "calibration = []\n",
    "\n",
    "for target_fpr in target_fprs:\n",
    "    idx = np.where(fpr <= target_fpr)[0]\n",
    "    if len(idx) > 0:\n",
    "        best_idx = idx[-1]\n",
    "        calibration.append({\n",
    "            'Target FPR': target_fpr,\n",
    "            'Actual FPR': fpr[best_idx],\n",
    "            'TPR': tpr[best_idx],\n",
    "            'Threshold': thresholds[best_idx],\n",
    "        })\n",
    "\n",
    "calibration_df = pd.DataFrame(calibration)\n",
    "print(\"\\nCalibration Table:\")\n",
    "calibration_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "## 8. Generate Validation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build report\n",
    "report = {\n",
    "    'AUC': float(roc_auc),\n",
    "    'TPR_at_FPR05': float(tpr_at_fpr05),\n",
    "    'threshold_tau': float(threshold_at_fpr05),\n",
    "    'cv_AUC_mean': float(cv_scores.mean()),\n",
    "    'cv_AUC_std': float(cv_scores.std()),\n",
    "    'median_residuals': {\n",
    "        'gold': float(df[df['label'] == 'gold']['residual'].median()),\n",
    "        'creative': float(df[df['label'] == 'creative']['residual'].median()),\n",
    "        'drift': float(df[df['label'] == 'drift']['residual'].median()),\n",
    "    },\n",
    "    'num_runs_per_label': {\n",
    "        'gold': len(traces['gold']),\n",
    "        'creative': len(traces['creative']),\n",
    "        'drift': len(traces['drift']),\n",
    "    },\n",
    "    'feature_importance': importance.to_dict('records'),\n",
    "    'calibration_table': calibration,\n",
    "    'rank_k': K,\n",
    "    'synthetic_data': True,\n",
    "}\n",
    "\n",
    "# Save report\n",
    "report_dir = PROJECT_ROOT / 'reports' / 'spectral_validation' / 'notebook'\n",
    "report_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(report_dir / 'validation_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"\\nValidation Report Saved!\")\n",
    "print(json.dumps(report, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "### Key Results\n",
    "\n",
    "| Metric | Value | Threshold | Status |\n",
    "|--------|-------|-----------|--------|\n",
    "| AUC | {AUC} | >= 0.90 | {PASS/FAIL} |\n",
    "| TPR @ FPR=0.05 | {TPR} | >= 0.80 | {PASS/FAIL} |\n",
    "\n",
    "### Observations\n",
    "\n",
    "1. **Residual** is a strong discriminator between drift and non-drift\n",
    "2. **Davis-Kahan angle** provides geometric insight into subspace perturbation\n",
    "3. **Koopman residual** captures temporal prediction error\n",
    "4. The combination achieves reliable detection with low false positive rate\n",
    "\n",
    "### Note\n",
    "All data used in this validation are **synthetic**. No real secrets or external network calls were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation check\n",
    "auc_pass = roc_auc >= 0.90\n",
    "tpr_pass = tpr_at_fpr05 >= 0.80\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"AUC: {roc_auc:.4f} {'PASS' if auc_pass else 'WARN'} (threshold: 0.90)\")\n",
    "print(f\"TPR @ FPR=0.05: {tpr_at_fpr05:.4f} {'PASS' if tpr_pass else 'WARN'} (threshold: 0.80)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if auc_pass and tpr_pass:\n",
    "    print(\"\\n[SUCCESS] All validation criteria met!\")\n",
    "else:\n",
    "    print(\"\\n[WARNING] Some criteria not met - review analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
