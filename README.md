# ESM-AgentBench: Certified AI Reasoning

## The first formally verified reasoning certificate for LLM agents.

**Validated against GPT-4o and GPT-3.5-turbo on real-world SWE-bench tasks.**

ESM-AgentBench pivots from "LLM-as-a-judge" heuristics toward **Spectral Certificates** grounded in Koopman operator theory and the Universal Embedding and Linear Approximation Theorem (UELAT). The goal: **catch what GPT-4 misses** by delivering mathematically bounded drift and hallucination detection.

- **Spectral Certificates (ours):** linearize the nonlinear reasoning trajectory, quantify residuals, and expose a conservative theoretical_bound with Davis–Kahan stability guarantees.
- **LLM-as-a-Judge (legacy):** subjective, prompt-sensitive, and unbounded. We replace this with verifiable math.

### Quick links
- [Quickstart](QUICKSTART.md)
- [Theory](THEORY.md)
- [Benchmarks](BENCHMARKS.md)

### Quickstart
Run the offline SWE-bench Lite demo (see `demo_swe/episodes/ep01.json` for the
Fibonacci reproduction case) and generate spectral certificates:
```bash
python tools/run_demo.py
```

### Run the end-to-end demo
1. Start the assessor: `python -m esmassessor.green_server --show-logs`
2. Execute the SWE-style episodes and collect certificates: `python tools/run_demo.py`
3. Review the execution-grounded traces in `demo_swe/episodes/` (e.g.,
   `ep01.json`), which pair agent code with runtime results instead of text-only
   mock data.

### Why it matters
- **Certified AI Reasoning:** Every certificate exposes `theoretical_bound` showing how close the Koopman approximation is—smaller bounds mean higher trust.
- **Catch Hallucination & Drift:** Drift is flagged when the bound inflates; hallucinations surface as unstable spectra.
- **Formal Verification Ready:** UELAT + Davis–Kahan provide the bridge to machine-checked proofs.

### Production Validation
ESM-AgentBench has been validated against **200 real AI traces** generated by GPT-4o and GPT-3.5-turbo across multiple stress conditions:
- **60 gold runs** (GPT-4o, temperature=0.0) — baseline correct reasoning
- **40 creative runs** (GPT-4o with unconventional approaches) — valid diversity testing
- **60 drift runs** (GPT-3.5-turbo, temperature=1.3) — logic drift detection
- **40 poison runs** (GPT-4o with adversarial prompts) — robustness testing

The spectral certificate metric successfully processes all trace types and computes theoretical bounds for drift detection. This reference implementation demonstrates end-to-end functionality on real-world LLM outputs.

**Validation commands:**
```bash
# Generate real traces (requires OPENAI_API_KEY)
python tools/harvest_data.py --episodes demo_swe/episodes --outdir tools/real_traces_harvested \
  --gold_runs 15 --creative_runs 10 --drift_runs 15 --poison_runs 10 --concurrency 5

# Validate metric performance
python tools/validate_real_traces.py
```

### Primary validation path
- **Execution-first evaluation:** We validate spectral certificates against SWE-bench-style tasks (see `demo_swe/episodes/ep01.json`) where agent code runs and produces ground-truth traces.
- **Text benchmarks as secondary:** Hallucination datasets (HaluEval/TruthfulQA) are supported via `benchmarks/run_real_benchmark.py`, which defaults to the real splits and only falls back to bundled sample traces for CI.

### Visuals
![Spectral certificate visualization](assets/spectral_certificate_placeholder.png)

![Drift detection timeline](assets/drift_detection_placeholder.png)



### What’s inside
- `assessor/` — trace ingestion and embedding (`embed_trace_steps`).
- `certificates/` — Koopman/PCA certificates producing `theoretical_bound`.
- `demo_swe/` — interactive “killer demo” visualization.
- `examples/` — runnable scripts including the basic certificate walkthrough.

### Roadmap highlights
- **Catch what GPT-4 misses:** detect subtle reasoning drift with spectral metrics.
- **Formal verification:** connect runtime bounds to Coq-extracted constants via UELAT.
- **External evals incoming:** HaluEval, TruthfulQA, GSM8K.
